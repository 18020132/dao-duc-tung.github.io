<!DOCTYPE html>
<html lang="en-US">
  <head>
  <meta charset="UTF-8" />

     
  <title>UMLS - Model Development - Part 2 - Evaluation</title>
  

  <meta name="description" content="AI Engineer Skills" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="theme-color" content="#157878" />
  <link rel="shortcut icon" href="/assets/images/favicon-32x32.ico" />
  <link rel="stylesheet" href="/assets/css/styles.css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons" />
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116933686-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag('js', new Date());

  gtag('config', 'UA-116933686-1');
</script>

<!-- Google search -->
<script async src="https://cse.google.com/cse.js?cx=3b3c3574614bf1b79"></script>
<script>
  function copyToClipboard(text) {
    var dummy = document.createElement('input');

    document.body.appendChild(dummy);
    dummy.value = text;
    dummy.select();
    document.execCommand('copy');
    document.body.removeChild(dummy);
  }
</script>

</head>

  <body>
    <section class="page-header">
  <div class="page-header-left">
    <a href="/">
      <img
        class="logo"
        src="/assets/images/logo-for-transparent-bg.png"
        alt="AI Engineer - Stay foolish!"
      />
    </a>
  </div>
  <div class="page-header-right">
    <div class="gcse-search"></div>
  </div>
  <div class="page-header-menu">
    
    <a href="/thoughts-on" class="btn">Thoughts On</a>
    
    <a href="/ml-skills" class="btn">ML Skills</a>
    
    <a href="/projects" class="btn">Projects</a>
    
  </div>
</section>

    <section class="main-content">
      <div class="pre-body">
   
   
  <a href="/ml-skills/the-ultimate-machine-learning-system" class="btn"> Back to The Ultimate Machine Learning System </a>
    
  <h1>UMLS - Model Development - Part 2 - Evaluation</h1>

  <div class="post-info">
    Apr 27, 2022 Â· 4 min read
  </div>
</div>

      <div class="mid-body"><p><img src="/assets/images/ml-skills/the-ultimate-machine-learning-system/model-development-part-2-evaluation/assessment.jpg" alt="assessment"></p>
<p>Model evaluation helps us to decide if one ML algorithm is better than another. Ideally, the evaluation methods should be the same in both the development and production environments. In practice, we might not have ground truths to evaluate models. This post covers the methods to evaluate models in development environments. For evaluating models in production, we will discuss in a future post.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#baseline">Baseline</a> </li>
<li><a href="#evaluation-methods">Evaluation methods</a> </li>
</ol>
<h2 id="baseline">Baseline</h2>
<p>Evaluation metrics are only helpful when comparing against baselines. Below is the list of common baselines.</p>
<p><strong>Random baseline</strong></p>
<ul>
<li>Use a normal/uniform random distribution</li>
<li>Use the same distribution as the label distribution</li>
</ul>
<p><strong>Simple heuristic</strong></p>
<ul>
<li>Use chronological order</li>
<li>Zero rule baseline: use the most common class as predictions</li>
</ul>
<p><strong>Human baseline</strong></p>
<ul>
<li>Compare to human experts</li>
</ul>
<p><strong>Existing solutions</strong></p>
<ul>
<li>Current existing solution</li>
<li>Third-party solution</li>
</ul>
<h2 id="evaluation-methods">Evaluation methods</h2>
<p>This section won&#39;t discuss the common evaluation methods to assess the model&#39;s performance. We will discuss the methods to evaluate the model&#39;s characteristics such as robustness, fairness, calibrated, and making sense.</p>
<p><strong>Perturbation test</strong></p>
<p>Add noise to the test data to create perturbed data. The more sensitive the model is to noise, the harder it will be to maintain.</p>
<p><strong>Invariance test</strong></p>
<p>Change the input&#39;s sensitive information to see if the output changes. Better, the sensitive information should be excluded when training the model. Certain changes to the inputs shouldn&#39;t lead to changes in the output.</p>
<p><strong>Directional expectation test</strong></p>
<p>Change an input&#39;s feature to see if the output changes in the expected direction. Certain changes to the inputs should cause predictable changes in outputs.</p>
<p><strong>Confidence measurement</strong></p>
<p>Confidence measurement is the threshold considered to be useful for each prediction. If this threshold is not selected wisely, it may annoy and make users lose trust in the system. In this confidence measurement, we need to consider:</p>
<ul>
<li>How do we measure that threshold?</li>
<li>What do we want to do with predictions below that threshold? Discard it, loop in humans, or ask for more information from users?</li>
</ul>
<p><strong>Slice-based evaluation</strong></p>
<p>Look at the model&#39;s performance on the subgroups of data instead of just using the coarse-grained metrics like overall F1 or accuracy on the entire dataset. Sometimes, a trend appears in several groups of data but disappears or reverses when the groups are combined. This phenomenon is called <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simplson&#39;s paradox</a>. Some subgroups examples are majority classes vs. minority classes, paid users vs. non-paid users.</p>
<p>Selecting the critical slices is more of an art than a science, requiring intensive data exploration and analysis. Below are the three main approaches:</p>
<ul>
<li>Heuristics-based: slice data using existing knowledge of the data and the task. Eg: in web traffic, slice data along dimensions like mobile vs. desktop, browser types, and locations.</li>
<li>Error analysis: find patterns among the misclassified examples.</li>
<li>Slice finder: uses algorithms such as beam search, and clustering. Eg: <a href="https://ieeexplore.ieee.org/abstract/document/8731353">Slice Finder: Automated Data Slicing for Model Validation</a>, <a href="https://jcst.ict.ac.cn/EN/10.1007/s11390-016-1647-1">Subgroup Discovery Algorithms: A Survey and Empirical Evaluation</a>.</li>
</ul>
<p><strong>Model calibration</strong>: Our model usually returns probabilities. A well-calibrated model is a model that returns probabilities of outcome A that match the real probabilities of that outcome A in production (given a big enough number of data to consider <em>matched</em>). This topic merits a dedicated post. For more details, please check <a href="https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html">Why model calibration matters and how to achieve it</a>, <a href="https://youtu.be/hWb-MIXKe-s">video 1</a>, <a href="https://youtu.be/AunotauS5yI">video 2</a>.</p>
<p><strong>Data testing</strong></p>
<p>For data, we need to test the following things.</p>
<ul>
<li>Test feature correlation, multiplicity, label quality, missing values</li>
<li>Test assumption about features, data distribution, pre-train data, post-train data</li>
<li>Check feature meaning</li>
</ul>
<p><strong>Pipeline testing</strong></p>
<p>For system pipeline, we need to test:</p>
<ul>
<li>The consistency of feature engineering in training and inference</li>
<li>The consistency of predictions in training, inference, and on multiple runs</li>
<li>The reproducibility of the pipeline (fix the random seed)</li>
<li>Test the edge case by giving an invalid input</li>
</ul>
<p><strong>System benchmarking</strong></p>
<p>We need to perform several actions as below.</p>
<ul>
<li>Reproducible experiments: log hyperparameters, metrics, rules, etc.</li>
<li>Development guide: documents</li>
<li>Track progress: benchmark dataset</li>
<li>Metrics to compare: latency, memory usage, prediction cost, accuracy, etc.</li>
<li>Compare with other systems: <code>MLPerf</code></li>
</ul>
<!-- MARKDOWN LINKS & IMAGES -->

</div>
      <div class="post-body">
  

  <div class="post-body-social">
    <div class="post-body-social-left">
      <div class="post-body-tags">
        <ul>
          
          <li><a href="#">ultimate</a></li>
          
          <li><a href="#">machine learning system</a></li>
          
          <li><a href="#">model evaluation</a></li>
          
          <li><a href="#">baseline</a></li>
          
          <li><a href="#">perturbation test</a></li>
          
          <li><a href="#">invariance test</a></li>
          
          <li><a href="#">directional expectation test</a></li>
          
          <li><a href="#">confidence measurement</a></li>
          
          <li><a href="#">slice-based evaluation</a></li>
          
          <li><a href="#">model calibration</a></li>
          
        </ul>
      </div>
    </div>
    <div class="post-body-social-right">
      <a
        href="#"
        onclick="copyToClipboard(window.location.host + '/ml-skills/the-ultimate-machine-learning-system/model-development-part-2-evaluation'); return false;"
        class="btn"
        ><i class="material-icons"> link </i></a
      >
    </div>
  </div>
  <div class="post-body-continue">
    
    <div class="post-body-continue-left">
      
      <a href="/ml-skills/the-ultimate-machine-learning-system/model-development-part-1-training" class="btn">
        <i class="material-icons"> arrow_back_ios </i>
        Previous<span class="post-body-continue-post-title">: UMLS - Model Development - Part 1 - Training</span></a
      >
      
    </div>
    <div class="post-body-continue-right">
      
      <a href="/ml-skills/the-ultimate-machine-learning-system/deployment-part-1-what-to-consider" class="btn">
        Next<span class="post-body-continue-post-title">: UMLS - Deployment - Part 1 - What to consider</span>
        <i class="material-icons"> arrow_forward_ios </i>
      </a>
      
    </div>
  </div>
</div>
<div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
    var PAGE_URL = site.basePath + '/' + post.url;
    var PAGE_IDENTIFIER = PAGE_URL;
    this.page.url = PAGE_URL;
    this.page.identifier = PAGE_IDENTIFIER;
  };
  (function () {
    // DON'T EDIT BELOW THIS LINE
    var d = document,
      s = d.createElement('script');
    s.src = 'https://ai-engineer.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript
  >Please enable JavaScript to view the
  <a href="https://disqus.com/?ref_noscript">comments.</a></noscript
>

    </section>
    <footer class="site-footer">
  <div class="footer-left">
    <a href="/">
      <img
        class="logo"
        src="/assets/images/logo-for-black-bg.png"
        alt="AI Engineer - Stay foolish!"
      />
    </a>
  </div>
  <div class="footer-right">
    <a href="/" class="site-footer-credits">AI Engineer @ 2022</a>
  </div>
</footer>

  </body>
</html>
